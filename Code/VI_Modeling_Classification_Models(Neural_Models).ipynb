{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0e01fd5",
   "metadata": {},
   "source": [
    "\n",
    "# Predicting Customer Satisfaction on Rent the Runway\n",
    "\n",
    "## VI. Modeling (Neural Network) \n",
    "### Katrin Ayrapetov\n",
    "\n",
    "\n",
    "<font style=\"font-size: 2rem; color: blue\">\n",
    "\n",
    "\n",
    " \n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "849b6c81",
   "metadata": {},
   "source": [
    "### Overview of the Notebook: \n",
    "\n",
    "#### In this notebook a Neural Network is built to classify the data.  \n",
    "**Feature Variables:** Type_of_Customer, Size, Overall_fit, Rented_for,Size_usually_worn, Height, Age, Bust_size, Body_type,\n",
    "Weight, Date, Brand, Rent_price, Number_of_reviews,\n",
    "       BMI, Sleeves, Neckline, Dress_Style, kfold, Height_binned,\n",
    "       Age_binned, Weight_binned, Rent_price_binned,\n",
    "       Number_of_reviews_binned, BMI_binned\n",
    "\n",
    "\n",
    "**Target Variable:**\n",
    "1: Not Satisfied with Rental (Satisfaction Rating of 1,2,3 stars) \n",
    "0: Satisfied with Rental (Satisfaction Rating 4,5 stars)\n",
    "\n",
    "<br> **For the Neural Network**\n",
    "<br>&emsp;&emsp;The numerical data was turned into categorical by binning along the 10 percentiles.  \n",
    "<br>&emsp;&emsp;Entity embedding was used on all the features. \n",
    "<br>&emsp;&emsp;An Additional Batch Normalization Layer was added. \n",
    "\n",
    "\n",
    "<br> **Metrics for the Network**\n",
    "<br>&emsp;&emsp; Accuracy:  0.8479\n",
    "<br>&emsp;&emsp; ROC AUC: 0.81281\n",
    "<br>&emsp;&emsp; Precision:  0.5581\n",
    "<br>&emsp;&emsp; Recall:  0.51473\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db9f0369",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, roc_auc_score, balanced_accuracy_score, ConfusionMatrixDisplay\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import os\n",
    "import gc\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import metrics, preprocessing\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras import callbacks\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import utils\n",
    "from sklearn import model_selection\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45c4495b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import seed\n",
    "seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4476bb81",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the Data Set \n",
    "df =  pd.read_csv('../Data/df_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec3edefb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Binarize the Predictor Variable: Satisfaction Rating \n",
    "# 1: Not Satisfied with Rental (Satisfaction Rating of 1,2,3) \n",
    "# 0: Satisfied with Rental (Satisfaction Rating 4,5)\n",
    "df['Rating'] = np.where(df['Rating'] <= 3, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b79f85cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.832324\n",
       "1    0.167676\n",
       "Name: Rating, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We are dealing with an unbalanced class. \n",
    "df[\"Rating\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c13c389",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type_of_Customer</th>\n",
       "      <th>Size</th>\n",
       "      <th>Overall_fit</th>\n",
       "      <th>Rented_for</th>\n",
       "      <th>Size_usually_worn</th>\n",
       "      <th>Height</th>\n",
       "      <th>Age</th>\n",
       "      <th>Bust_size</th>\n",
       "      <th>Body_type</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Date</th>\n",
       "      <th>Brand</th>\n",
       "      <th>Retail_price</th>\n",
       "      <th>Rent_price</th>\n",
       "      <th>Number_of_reviews</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Sleeves</th>\n",
       "      <th>Neckline</th>\n",
       "      <th>Dress_Style</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TOP CONTRIBUTOR</td>\n",
       "      <td>S</td>\n",
       "      <td>Overall fit: True to Size</td>\n",
       "      <td>Vacation</td>\n",
       "      <td>8</td>\n",
       "      <td>66</td>\n",
       "      <td>31</td>\n",
       "      <td>34C</td>\n",
       "      <td>athletic</td>\n",
       "      <td>142</td>\n",
       "      <td>0</td>\n",
       "      <td>spring</td>\n",
       "      <td>Tory Burch</td>\n",
       "      <td>478</td>\n",
       "      <td>70</td>\n",
       "      <td>33</td>\n",
       "      <td>22.916896</td>\n",
       "      <td>sleeveless</td>\n",
       "      <td>square_neckline</td>\n",
       "      <td>hourglass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TOP CONTRIBUTOR</td>\n",
       "      <td>M</td>\n",
       "      <td>Overall fit: Large</td>\n",
       "      <td>Wedding</td>\n",
       "      <td>6</td>\n",
       "      <td>67</td>\n",
       "      <td>33</td>\n",
       "      <td>36C</td>\n",
       "      <td>hourglass</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>spring</td>\n",
       "      <td>Tory Burch</td>\n",
       "      <td>478</td>\n",
       "      <td>70</td>\n",
       "      <td>33</td>\n",
       "      <td>23.490755</td>\n",
       "      <td>sleeveless</td>\n",
       "      <td>square_neckline</td>\n",
       "      <td>hourglass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TOP CONTRIBUTOR</td>\n",
       "      <td>S</td>\n",
       "      <td>Overall fit: Large</td>\n",
       "      <td>Everyday</td>\n",
       "      <td>6</td>\n",
       "      <td>66</td>\n",
       "      <td>27</td>\n",
       "      <td>34B</td>\n",
       "      <td>pear</td>\n",
       "      <td>140</td>\n",
       "      <td>0</td>\n",
       "      <td>spring</td>\n",
       "      <td>Tory Burch</td>\n",
       "      <td>478</td>\n",
       "      <td>70</td>\n",
       "      <td>33</td>\n",
       "      <td>22.594123</td>\n",
       "      <td>sleeveless</td>\n",
       "      <td>square_neckline</td>\n",
       "      <td>hourglass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TOP CONTRIBUTOR</td>\n",
       "      <td>L</td>\n",
       "      <td>Overall fit: True to Size</td>\n",
       "      <td>unknown</td>\n",
       "      <td>12</td>\n",
       "      <td>66</td>\n",
       "      <td>42</td>\n",
       "      <td>36B</td>\n",
       "      <td>pear</td>\n",
       "      <td>181</td>\n",
       "      <td>0</td>\n",
       "      <td>spring</td>\n",
       "      <td>Tory Burch</td>\n",
       "      <td>478</td>\n",
       "      <td>70</td>\n",
       "      <td>33</td>\n",
       "      <td>29.210973</td>\n",
       "      <td>sleeveless</td>\n",
       "      <td>square_neckline</td>\n",
       "      <td>hourglass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TOP CONTRIBUTOR</td>\n",
       "      <td>L</td>\n",
       "      <td>Overall fit: True to Size</td>\n",
       "      <td>Everyday</td>\n",
       "      <td>12</td>\n",
       "      <td>70</td>\n",
       "      <td>48</td>\n",
       "      <td>34D</td>\n",
       "      <td>pear</td>\n",
       "      <td>165</td>\n",
       "      <td>0</td>\n",
       "      <td>spring</td>\n",
       "      <td>Tory Burch</td>\n",
       "      <td>478</td>\n",
       "      <td>70</td>\n",
       "      <td>33</td>\n",
       "      <td>23.672449</td>\n",
       "      <td>sleeveless</td>\n",
       "      <td>square_neckline</td>\n",
       "      <td>hourglass</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Type_of_Customer Size                Overall_fit Rented_for  \\\n",
       "0  TOP CONTRIBUTOR    S  Overall fit: True to Size   Vacation   \n",
       "1  TOP CONTRIBUTOR    M         Overall fit: Large    Wedding   \n",
       "2  TOP CONTRIBUTOR    S         Overall fit: Large   Everyday   \n",
       "3  TOP CONTRIBUTOR    L  Overall fit: True to Size    unknown   \n",
       "4  TOP CONTRIBUTOR    L  Overall fit: True to Size   Everyday   \n",
       "\n",
       "  Size_usually_worn  Height  Age Bust_size  Body_type  Weight  Rating    Date  \\\n",
       "0                 8      66   31       34C   athletic     142       0  spring   \n",
       "1                 6      67   33       36C  hourglass     150       0  spring   \n",
       "2                 6      66   27       34B       pear     140       0  spring   \n",
       "3                12      66   42       36B       pear     181       0  spring   \n",
       "4                12      70   48       34D       pear     165       0  spring   \n",
       "\n",
       "        Brand  Retail_price  Rent_price  Number_of_reviews        BMI  \\\n",
       "0  Tory Burch           478          70                 33  22.916896   \n",
       "1  Tory Burch           478          70                 33  23.490755   \n",
       "2  Tory Burch           478          70                 33  22.594123   \n",
       "3  Tory Burch           478          70                 33  29.210973   \n",
       "4  Tory Burch           478          70                 33  23.672449   \n",
       "\n",
       "      Sleeves         Neckline Dress_Style  \n",
       "0  sleeveless  square_neckline   hourglass  \n",
       "1  sleeveless  square_neckline   hourglass  \n",
       "2  sleeveless  square_neckline   hourglass  \n",
       "3  sleeveless  square_neckline   hourglass  \n",
       "4  sleeveless  square_neckline   hourglass  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6e5c4fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a target variable vector. \n",
    "y = df.Rating.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cfb1a5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Because the target class is unbalanced, use the k-fold method to create 5 k-folds. \n",
    "\n",
    "#initiate the kfold class from model_selection module\n",
    "#The folds are made by preserving the percentage of samples for each class.\n",
    "kf = model_selection.StratifiedKFold(n_splits=5)\n",
    "\n",
    "#Create a column to hold kfold labels \n",
    "df[\"kfold\"] = -1\n",
    "\n",
    "#Reshuffle the rows. \n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "for f, (t_,v_) in enumerate(kf.split(X=df,y=y)):\n",
    "    df.loc[v_,\"kfold\"] = f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fa3c7104",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    31287\n",
       "1    31287\n",
       "2    31287\n",
       "3    31286\n",
       "4    31286\n",
       "Name: kfold, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check that the same number of observations is in each fold. \n",
    "df.kfold.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2a757c41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: k = 0\n",
      "0    0.832454\n",
      "1    0.167546\n",
      "Name: Rating, dtype: float64\n",
      "fold: k = 1\n",
      "0    0.83124\n",
      "1    0.16876\n",
      "Name: Rating, dtype: float64\n",
      "fold: k = 2\n",
      "0    0.834212\n",
      "1    0.165788\n",
      "Name: Rating, dtype: float64\n",
      "fold: k = 3\n",
      "0    0.829732\n",
      "1    0.170268\n",
      "Name: Rating, dtype: float64\n",
      "fold: k = 4\n",
      "0    0.833983\n",
      "1    0.166017\n",
      "Name: Rating, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#Check that the target variable has the same distribution  the same in each fold. \n",
    "for k in range(5):\n",
    "    print(f\"fold: k = {k}\")\n",
    "    print(df[df.kfold==k].Rating.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "21415bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop Unnecessary Columns \n",
    "df.drop(columns=[\"Retail_price\"],inplace=True)\n",
    "df.dropna(inplace=True)\n",
    "df = df.reset_index()\n",
    "df.drop(columns=\"index\",inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "20214ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert the numeric columns to categories split along the 10 percentiles.\n",
    "num_columns = ['Height', 'Age', 'Weight', 'Rent_price', 'Number_of_reviews', 'BMI']\n",
    "for column in num_columns: \n",
    "    df[f\"{column}_binned\"] = pd.qcut(x = df[column], q = 10, labels=False, retbins=False, precision=3, duplicates='drop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cac2e955",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function creates the Neural Network model using Entity embedding. \n",
    "def create_model(data, catcols):\n",
    "    inputs = []\n",
    "    outputs = []\n",
    "    for c in catcols:\n",
    "        num_unique_values = int(data[c].nunique())\n",
    "        embed_dim = int(min(np.ceil((num_unique_values)/2), 50))\n",
    "        inp = layers.Input(shape=(1,))\n",
    "        out = layers.Embedding(num_unique_values + 1, embed_dim, name=c)(inp)\n",
    "        out = layers.SpatialDropout1D(0.3)(out)\n",
    "        out = layers.Reshape(target_shape=(embed_dim, ))(out)\n",
    "        inputs.append(inp)\n",
    "        outputs.append(out)\n",
    "    # NEED TO ADD SOMETHING FOR NUMERIC FEATURES HERE## \n",
    "    # Add numericals to the outputs as tensors \n",
    "    x = layers.Concatenate()(outputs)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dense(45, activation=\"relu\")(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dense(45, activation=\"relu\")(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    y = layers.Dense(2, activation=\"softmax\")(x)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=y)\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4badbbbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function label encodes categorical features. It fits the training data with a model. \n",
    "# then uses the model to make predictions on the submissions data set. \n",
    "def neural_network_model(fold):\n",
    "   \n",
    "    #list of numeric columns \n",
    "    num_cols = ['Height', 'Age', 'Weight', 'Rent_price', 'Number_of_reviews', 'BMI']\n",
    "    cat_cols = ['Type_of_Customer','Size','Overall_fit','Rented_for','Size_usually_worn','Bust_size','Body_type','Date','Brand','Sleeves','Neckline','Dress_Style']\n",
    "    #All columns are features except the target column and the kfold column \n",
    "    features = ['Type_of_Customer', 'Size',  'Rented_for',\n",
    "       'Size_usually_worn', 'Height', 'Age', 'Bust_size', 'Body_type',\n",
    "       'Weight', 'Date', 'Brand', 'Rent_price', 'Number_of_reviews',\n",
    "       'BMI', 'Sleeves', 'Neckline', 'Dress_Style', \n",
    "       'Age_binned', 'Weight_binned', 'Rent_price_binned',\n",
    "       'Number_of_reviews_binned', 'BMI_binned']\n",
    "    \n",
    "    \n",
    "    #convert the categorical variables to strings\n",
    "    for col in features:\n",
    "        df.loc[:,col] = df[col].astype(str)  \n",
    "    #Use label encoder on categorical features. \n",
    "    for feat in features:\n",
    "        lbl_enc = preprocessing.LabelEncoder()\n",
    "        df.loc[:,feat]=lbl_enc.fit_transform(df[feat].values)\n",
    "    \n",
    "        \n",
    "    #Hold one of the five folds as validation set and four folds as training sets \n",
    "    df_train = df[df.kfold != fold].reset_index(drop=True)\n",
    "    df_valid = df[df.kfold == fold].reset_index(drop=True)\n",
    "    \n",
    "    model = create_model(df,features)\n",
    "    \n",
    "    # Features \n",
    "    xtrain = [\n",
    "     df_train[features].values[:, k] for k in range(len(features))\n",
    "    ]\n",
    "    xvalid = [\n",
    "    df_valid[features].values[:, k] for k in range(len(features))\n",
    "    ]\n",
    "\n",
    "    # get target columns\n",
    "    ytrain = df_train.Rating.values\n",
    "    yvalid = df_valid.Rating.values\n",
    "    \n",
    "    # convert target columns to categories\n",
    "\n",
    "    ytrain_cat = utils.to_categorical(ytrain)\n",
    "    yvalid_cat = utils.to_categorical(yvalid)\n",
    "    \n",
    "    # fit the model\n",
    "    model.fit(xtrain,\n",
    "    ytrain_cat,\n",
    "    validation_data=(xvalid, yvalid_cat),\n",
    "    verbose=0,\n",
    "    batch_size=16,\n",
    "    epochs=100)\n",
    "    \n",
    "    valid_preds = model.predict(xvalid)[:, 1]\n",
    "    \n",
    "    train_preds = model.predict(xtrain)[:,1]\n",
    "    \n",
    "    auc_valid = metrics.roc_auc_score(yvalid, valid_preds)\n",
    "    auc_train = metrics.roc_auc_score(ytrain, train_preds)\n",
    "    \n",
    "    print(f\"Fold = {fold}, AUC_train = {auc_train}, AUC_test = {auc_valid}\")\n",
    "    return ytrain, train_preds, yvalid, valid_preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2a9d68b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold = 3, AUC_train = 0.8650323707759539, AUC_test = 0.8128193921024311\n"
     ]
    }
   ],
   "source": [
    "ytrain_3, train_preds_3, yvalid_3, valid_preds_3 = neural_network_model(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "21a7ca87",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_results_3= pd.DataFrame(data=[ytrain_3, train_preds_3]).T\n",
    "df_train_results_3.columns=[\"True_Train_Classes\",\"Pred_Train_Classes\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "100ccefc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_results_3= pd.DataFrame(data=[yvalid_3, valid_preds_3]).T\n",
    "df_test_results_3.columns=[\"True_Test_Classes\",\"Pred_Test_Classes\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4b4a2708",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_results_3['Pred_Train_Classes_binarized'] = np.where(df_train_results_3['Pred_Train_Classes'] >= 0.15, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ea4deae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_results_3['Pred_Test_Classes_binarized'] = np.where(df_test_results_3['Pred_Test_Classes'] >= 0.15, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2a916380",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Accuracy: 0.8705042869585368\n",
      "Validation Set Accuracy: 0.847983123441795\n"
     ]
    }
   ],
   "source": [
    "#Accuracy \n",
    "accuracy_train = metrics.accuracy_score(df_train_results_3.True_Train_Classes.values,\n",
    "                                  df_train_results_3.Pred_Train_Classes_binarized.values)\n",
    "accuracy_test = metrics.accuracy_score(df_test_results_3.True_Test_Classes.values,\n",
    "                                       df_test_results_3.Pred_Test_Classes_binarized.values)\n",
    "\n",
    "print(f\"Training Set Accuracy: {accuracy_train}\")\n",
    "print(f\"Validation Set Accuracy: {accuracy_test}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f5e2cef6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Recall: 0.5676218724584988\n",
      "Validation Set Recall: 0.514736249296039\n"
     ]
    }
   ],
   "source": [
    "#Recall \n",
    "recall_train = metrics.recall_score(df_train_results_3.True_Train_Classes.values,\n",
    "                                  df_train_results_3.Pred_Train_Classes_binarized.values)\n",
    "recall_test = metrics.recall_score(df_test_results_3.True_Test_Classes.values,\n",
    "                                       df_test_results_3.Pred_Test_Classes_binarized.values)\n",
    "\n",
    "print(f\"Training Set Recall: {recall_train}\")\n",
    "print(f\"Validation Set Recall: {recall_test}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ddcbac77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Precision: 0.6233909525560868\n",
      "Validation Set Precision: 0.5581111337268472\n"
     ]
    }
   ],
   "source": [
    "#Precision\n",
    "precision_train = metrics.precision_score(df_train_results_3.True_Train_Classes.values,\n",
    "                                  df_train_results_3.Pred_Train_Classes_binarized.values)\n",
    "precision_test = metrics.precision_score(df_test_results_3.True_Test_Classes.values,\n",
    "                                       df_test_results_3.Pred_Test_Classes_binarized.values)\n",
    "\n",
    "print(f\"Training Set Precision: {precision_train}\")\n",
    "print(f\"Validation Set Precision: {precision_test}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e965f103",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
